{"ast":null,"code":"var assert = require('assert'); // The Stream class\n// ================\n// Stream is a [Duplex stream](https://nodejs.org/api/stream.html#stream_class_stream_duplex)\n// subclass that implements the [HTTP/2 Stream](https://tools.ietf.org/html/rfc7540#section-5)\n// concept. It has two 'sides': one that is used by the user to send/receive data (the `stream`\n// object itself) and one that is used by a Connection to read/write frames to/from the other peer\n// (`stream.upstream`).\n\n\nvar Duplex = require('stream').Duplex;\n\nexports.Stream = Stream; // Public API\n// ----------\n// * **new Stream(log, connection)**: create a new Stream\n//\n// * **Event: 'headers' (headers)**: signals incoming headers\n//\n// * **Event: 'promise' (stream, headers)**: signals an incoming push promise\n//\n// * **Event: 'priority' (priority)**: signals a priority change. `priority` is a number between 0\n//     (highest priority) and 2^31-1 (lowest priority). Default value is 2^30.\n//\n// * **Event: 'error' (type)**: signals an error\n//\n// * **headers(headers)**: send headers\n//\n// * **promise(headers): Stream**: promise a stream\n//\n// * **priority(priority)**: set the priority of the stream. Priority can be changed by the peer\n//   too, but once it is set locally, it can not be changed remotely.\n//\n// * **reset(error)**: reset the stream with an error code\n//\n// * **upstream**: a [Flow](flow.js) that is used by the parent connection to write/read frames\n//   that are to be sent/arrived to/from the peer and are related to this stream.\n//\n// Headers are always in the [regular node.js header format][1].\n// [1]: https://nodejs.org/api/http.html#http_message_headers\n// Constructor\n// -----------\n// The main aspects of managing the stream are:\n\nfunction Stream(log, connection) {\n  Duplex.call(this); // * logging\n\n  this._log = log.child({\n    component: 'stream',\n    s: this\n  }); // * receiving and sending stream management commands\n\n  this._initializeManagement(); // * sending and receiving frames to/from the upstream connection\n\n\n  this._initializeDataFlow(); // * maintaining the state of the stream (idle, open, closed, etc.) and error detection\n\n\n  this._initializeState();\n\n  this.connection = connection;\n}\n\nStream.prototype = Object.create(Duplex.prototype, {\n  constructor: {\n    value: Stream\n  }\n}); // Managing the stream\n// -------------------\n// the default stream priority is 2^30\n\nvar DEFAULT_PRIORITY = Math.pow(2, 30);\nvar MAX_PRIORITY = Math.pow(2, 31) - 1; // PUSH_PROMISE and HEADERS are forwarded to the user through events.\n\nStream.prototype._initializeManagement = function _initializeManagement() {\n  this._resetSent = false;\n  this._priority = DEFAULT_PRIORITY;\n  this._letPeerPrioritize = true;\n};\n\nStream.prototype.promise = function promise(headers) {\n  var stream = new Stream(this._log, this.connection);\n  stream._priority = Math.min(this._priority + 1, MAX_PRIORITY);\n\n  this._pushUpstream({\n    type: 'PUSH_PROMISE',\n    flags: {},\n    stream: this.id,\n    promised_stream: stream,\n    headers: headers\n  });\n\n  return stream;\n};\n\nStream.prototype._onPromise = function _onPromise(frame) {\n  this.emit('promise', frame.promised_stream, frame.headers);\n};\n\nStream.prototype.headers = function headers(headers) {\n  this._pushUpstream({\n    type: 'HEADERS',\n    flags: {},\n    stream: this.id,\n    headers: headers\n  });\n};\n\nStream.prototype._onHeaders = function _onHeaders(frame) {\n  if (frame.priority !== undefined) {\n    this.priority(frame.priority, true);\n  }\n\n  this.emit('headers', frame.headers);\n};\n\nStream.prototype.priority = function priority(priority, peer) {\n  if (peer && this._letPeerPrioritize || !peer) {\n    if (!peer) {\n      this._letPeerPrioritize = false;\n      var lastFrame = this.upstream.getLastQueuedFrame();\n\n      if (lastFrame && (lastFrame.type === 'HEADERS' || lastFrame.type === 'PRIORITY')) {\n        lastFrame.priority = priority;\n      } else {\n        this._pushUpstream({\n          type: 'PRIORITY',\n          flags: {},\n          stream: this.id,\n          priority: priority\n        });\n      }\n    }\n\n    this._log.debug({\n      priority: priority\n    }, 'Changing priority');\n\n    this.emit('priority', priority);\n    this._priority = priority;\n  }\n};\n\nStream.prototype._onPriority = function _onPriority(frame) {\n  this.priority(frame.priority, true);\n}; // Resetting the stream. Normally, an endpoint SHOULD NOT send more than one RST_STREAM frame for\n// any stream.\n\n\nStream.prototype.reset = function reset(error) {\n  if (!this._resetSent) {\n    this._resetSent = true;\n\n    this._pushUpstream({\n      type: 'RST_STREAM',\n      flags: {},\n      stream: this.id,\n      error: error\n    });\n  }\n}; // Specify an alternate service for the origin of this stream\n\n\nStream.prototype.altsvc = function altsvc(host, port, protocolID, maxAge, origin) {\n  var stream;\n\n  if (origin) {\n    stream = 0;\n  } else {\n    stream = this.id;\n  }\n\n  this._pushUpstream({\n    type: 'ALTSVC',\n    flags: {},\n    stream: stream,\n    host: host,\n    port: port,\n    protocolID: protocolID,\n    origin: origin,\n    maxAge: maxAge\n  });\n}; // Data flow\n// ---------\n// The incoming and the generated outgoing frames are received/transmitted on the `this.upstream`\n// [Flow](flow.html). The [Connection](connection.html) object instantiating the stream will read\n// and write frames to/from it. The stream itself is a regular [Duplex stream][1], and is used by\n// the user to write or read the body of the request.\n// [1]: https://nodejs.org/api/stream.html#stream_class_stream_duplex\n//     upstream side                  stream                  user side\n//\n//                    +------------------------------------+\n//                    |                                    |\n//                    +------------------+                 |\n//                    |     upstream     |                 |\n//                    |                  |                 |\n//                    +--+               |              +--|\n//            read()  |  |  _send()      |    _write()  |  |  write(buf)\n//     <--------------|B |<--------------|--------------| B|<------------\n//                    |  |               |              |  |\n//            frames  +--+               |              +--|  buffers\n//                    |  |               |              |  |\n//     -------------->|B |---------------|------------->| B|------------>\n//      write(frame)  |  |  _receive()   |     _read()  |  |  read()\n//                    +--+               |              +--|\n//                    |                  |                 |\n//                    |                  |                 |\n//                    +------------------+                 |\n//                    |                                    |\n//                    +------------------------------------+\n//\n//     B: input or output buffer\n\n\nvar Flow = require('./flow').Flow;\n\nStream.prototype._initializeDataFlow = function _initializeDataFlow() {\n  this.id = undefined;\n  this._ended = false;\n  this.upstream = new Flow();\n  this.upstream._log = this._log;\n  this.upstream._send = this._send.bind(this);\n  this.upstream._receive = this._receive.bind(this);\n  this.upstream.write = this._writeUpstream.bind(this);\n  this.upstream.on('error', this.emit.bind(this, 'error'));\n  this.on('finish', this._finishing);\n};\n\nStream.prototype._pushUpstream = function _pushUpstream(frame) {\n  this.upstream.push(frame);\n\n  this._transition(true, frame);\n}; // Overriding the upstream's `write` allows us to act immediately instead of waiting for the input\n// queue to empty. This is important in case of control frames.\n\n\nStream.prototype._writeUpstream = function _writeUpstream(frame) {\n  this._log.debug({\n    frame: frame\n  }, 'Receiving frame');\n\n  var moreNeeded = Flow.prototype.write.call(this.upstream, frame); // * Transition to a new state if that's the effect of receiving the frame\n\n  this._transition(false, frame); // * If it's a control frame. Call the appropriate handler method.\n\n\n  if (frame.type === 'HEADERS') {\n    if (this._processedHeaders && !frame.flags['END_STREAM']) {\n      this.emit('error', 'PROTOCOL_ERROR');\n    }\n\n    this._processedHeaders = true;\n\n    this._onHeaders(frame);\n  } else if (frame.type === 'PUSH_PROMISE') {\n    this._onPromise(frame);\n  } else if (frame.type === 'PRIORITY') {\n    this._onPriority(frame);\n  } else if (frame.type === 'ALTSVC') {// TODO\n  } else if (frame.type === 'BLOCKED') {} // TODO\n  // * If it's an invalid stream level frame, emit error\n  else if (frame.type !== 'DATA' && frame.type !== 'WINDOW_UPDATE' && frame.type !== 'RST_STREAM') {\n      this._log.error({\n        frame: frame\n      }, 'Invalid stream level frame');\n\n      this.emit('error', 'PROTOCOL_ERROR');\n    }\n\n  return moreNeeded;\n}; // The `_receive` method (= `upstream._receive`) gets called when there's an incoming frame.\n\n\nStream.prototype._receive = function _receive(frame, ready) {\n  // * If it's a DATA frame, then push the payload into the output buffer on the other side.\n  //   Call ready when the other side is ready to receive more.\n  if (!this._ended && frame.type === 'DATA') {\n    var moreNeeded = this.push(frame.data);\n\n    if (!moreNeeded) {\n      this._receiveMore = ready;\n    }\n  } // * Any frame may signal the end of the stream with the END_STREAM flag\n\n\n  if (!this._ended && (frame.flags.END_STREAM || frame.type === 'RST_STREAM')) {\n    this.push(null);\n    this._ended = true;\n  } // * Postpone calling `ready` if `push()` returned a falsy value\n\n\n  if (this._receiveMore !== ready) {\n    ready();\n  }\n}; // The `_read` method is called when the user side is ready to receive more data. If there's a\n// pending write on the upstream, then call its pending ready callback to receive more frames.\n\n\nStream.prototype._read = function _read() {\n  if (this._receiveMore) {\n    var receiveMore = this._receiveMore;\n    delete this._receiveMore;\n    receiveMore();\n  }\n}; // The `write` method gets called when there's a write request from the user.\n\n\nStream.prototype._write = function _write(buffer, encoding, ready) {\n  // * Chunking is done by the upstream Flow.\n  var moreNeeded = this._pushUpstream({\n    type: 'DATA',\n    flags: {},\n    stream: this.id,\n    data: buffer\n  }); // * Call ready when upstream is ready to receive more frames.\n\n\n  if (moreNeeded) {\n    ready();\n  } else {\n    this._sendMore = ready;\n  }\n}; // The `_send` (= `upstream._send`) method is called when upstream is ready to receive more frames.\n// If there's a pending write on the user side, then call its pending ready callback to receive more\n// writes.\n\n\nStream.prototype._send = function _send() {\n  if (this._sendMore) {\n    var sendMore = this._sendMore;\n    delete this._sendMore;\n    sendMore();\n  }\n}; // When the stream is finishing (the user calls `end()` on it), then we have to set the `END_STREAM`\n// flag on the last frame. If there's no frame in the queue, or if it doesn't support this flag,\n// then we create a 0 length DATA frame. We could do this all the time, but putting the flag on an\n// existing frame is a nice optimization.\n\n\nvar emptyBuffer = new Buffer(0);\n\nStream.prototype._finishing = function _finishing() {\n  var endFrame = {\n    type: 'DATA',\n    flags: {\n      END_STREAM: true\n    },\n    stream: this.id,\n    data: emptyBuffer\n  };\n  var lastFrame = this.upstream.getLastQueuedFrame();\n\n  if (lastFrame && (lastFrame.type === 'DATA' || lastFrame.type === 'HEADERS')) {\n    this._log.debug({\n      frame: lastFrame\n    }, 'Marking last frame with END_STREAM flag.');\n\n    lastFrame.flags.END_STREAM = true;\n\n    this._transition(true, endFrame);\n  } else {\n    this._pushUpstream(endFrame);\n  }\n}; // [Stream States](https://tools.ietf.org/html/rfc7540#section-5.1)\n// ----------------\n//\n//                           +--------+\n//                     PP    |        |    PP\n//                  ,--------|  idle  |--------.\n//                 /         |        |         \\\n//                v          +--------+          v\n//         +----------+          |           +----------+\n//         |          |          | H         |          |\n//     ,---| reserved |          |           | reserved |---.\n//     |   | (local)  |          v           | (remote) |   |\n//     |   +----------+      +--------+      +----------+   |\n//     |      |          ES  |        |  ES          |      |\n//     |      | H    ,-------|  open  |-------.      | H    |\n//     |      |     /        |        |        \\     |      |\n//     |      v    v         +--------+         v    v      |\n//     |   +----------+          |           +----------+   |\n//     |   |   half   |          |           |   half   |   |\n//     |   |  closed  |          | R         |  closed  |   |\n//     |   | (remote) |          |           | (local)  |   |\n//     |   +----------+          |           +----------+   |\n//     |        |                v                 |        |\n//     |        |  ES / R    +--------+  ES / R    |        |\n//     |        `----------->|        |<-----------'        |\n//     |  R                  | closed |                  R  |\n//     `-------------------->|        |<--------------------'\n//                           +--------+\n// Streams begin in the IDLE state and transitions happen when there's an incoming or outgoing frame\n\n\nStream.prototype._initializeState = function _initializeState() {\n  this.state = 'IDLE';\n  this._initiated = undefined;\n  this._closedByUs = undefined;\n  this._closedWithRst = undefined;\n  this._processedHeaders = false;\n}; // Only `_setState` should change `this.state` directly. It also logs the state change and notifies\n// interested parties using the 'state' event.\n\n\nStream.prototype._setState = function transition(state) {\n  assert(this.state !== state);\n\n  this._log.debug({\n    from: this.state,\n    to: state\n  }, 'State transition');\n\n  this.state = state;\n  this.emit('state', state);\n}; // A state is 'active' if the stream in that state counts towards the concurrency limit. Streams\n// that are in the \"open\" state, or either of the \"half closed\" states count toward this limit.\n\n\nfunction activeState(state) {\n  return state === 'HALF_CLOSED_LOCAL' || state === 'HALF_CLOSED_REMOTE' || state === 'OPEN';\n} // `_transition` is called every time there's an incoming or outgoing frame. It manages state\n// transitions, and detects stream errors. A stream error is always caused by a frame that is not\n// allowed in the current state.\n\n\nStream.prototype._transition = function transition(sending, frame) {\n  var receiving = !sending;\n  var connectionError;\n  var streamError;\n  var DATA = false,\n      HEADERS = false,\n      PRIORITY = false,\n      ALTSVC = false,\n      BLOCKED = false;\n  var RST_STREAM = false,\n      PUSH_PROMISE = false,\n      WINDOW_UPDATE = false;\n\n  switch (frame.type) {\n    case 'DATA':\n      DATA = true;\n      break;\n\n    case 'HEADERS':\n      HEADERS = true;\n      break;\n\n    case 'PRIORITY':\n      PRIORITY = true;\n      break;\n\n    case 'RST_STREAM':\n      RST_STREAM = true;\n      break;\n\n    case 'PUSH_PROMISE':\n      PUSH_PROMISE = true;\n      break;\n\n    case 'WINDOW_UPDATE':\n      WINDOW_UPDATE = true;\n      break;\n\n    case 'ALTSVC':\n      ALTSVC = true;\n      break;\n\n    case 'BLOCKED':\n      BLOCKED = true;\n      break;\n  }\n\n  var previousState = this.state;\n\n  switch (this.state) {\n    // All streams start in the **idle** state. In this state, no frames have been exchanged.\n    //\n    // * Sending or receiving a HEADERS frame causes the stream to become \"open\".\n    //\n    // When the HEADERS frame contains the END_STREAM flags, then two state transitions happen.\n    case 'IDLE':\n      if (HEADERS) {\n        this._setState('OPEN');\n\n        if (frame.flags.END_STREAM) {\n          this._setState(sending ? 'HALF_CLOSED_LOCAL' : 'HALF_CLOSED_REMOTE');\n        }\n\n        this._initiated = sending;\n      } else if (sending && RST_STREAM) {\n        this._setState('CLOSED');\n      } else if (PRIORITY) {\n        /* No state change */\n      } else {\n        connectionError = 'PROTOCOL_ERROR';\n      }\n\n      break;\n    // A stream in the **reserved (local)** state is one that has been promised by sending a\n    // PUSH_PROMISE frame.\n    //\n    // * The endpoint can send a HEADERS frame. This causes the stream to open in a \"half closed\n    //   (remote)\" state.\n    // * Either endpoint can send a RST_STREAM frame to cause the stream to become \"closed\". This\n    //   releases the stream reservation.\n    // * An endpoint may receive PRIORITY frame in this state.\n    // * An endpoint MUST NOT send any other type of frame in this state.\n\n    case 'RESERVED_LOCAL':\n      if (sending && HEADERS) {\n        this._setState('HALF_CLOSED_REMOTE');\n      } else if (RST_STREAM) {\n        this._setState('CLOSED');\n      } else if (PRIORITY) {\n        /* No state change */\n      } else {\n        connectionError = 'PROTOCOL_ERROR';\n      }\n\n      break;\n    // A stream in the **reserved (remote)** state has been reserved by a remote peer.\n    //\n    // * Either endpoint can send a RST_STREAM frame to cause the stream to become \"closed\". This\n    //   releases the stream reservation.\n    // * Receiving a HEADERS frame causes the stream to transition to \"half closed (local)\".\n    // * An endpoint MAY send PRIORITY frames in this state to reprioritize the stream.\n    // * Receiving any other type of frame MUST be treated as a stream error of type PROTOCOL_ERROR.\n\n    case 'RESERVED_REMOTE':\n      if (RST_STREAM) {\n        this._setState('CLOSED');\n      } else if (receiving && HEADERS) {\n        this._setState('HALF_CLOSED_LOCAL');\n      } else if (BLOCKED || PRIORITY) {\n        /* No state change */\n      } else {\n        connectionError = 'PROTOCOL_ERROR';\n      }\n\n      break;\n    // The **open** state is where both peers can send frames. In this state, sending peers observe\n    // advertised stream level flow control limits.\n    //\n    // * From this state either endpoint can send a frame with a END_STREAM flag set, which causes\n    //   the stream to transition into one of the \"half closed\" states: an endpoint sending a\n    //   END_STREAM flag causes the stream state to become \"half closed (local)\"; an endpoint\n    //   receiving a END_STREAM flag causes the stream state to become \"half closed (remote)\".\n    // * Either endpoint can send a RST_STREAM frame from this state, causing it to transition\n    //   immediately to \"closed\".\n\n    case 'OPEN':\n      if (frame.flags.END_STREAM) {\n        this._setState(sending ? 'HALF_CLOSED_LOCAL' : 'HALF_CLOSED_REMOTE');\n      } else if (RST_STREAM) {\n        this._setState('CLOSED');\n      } else {\n        /* No state change */\n      }\n\n      break;\n    // A stream that is **half closed (local)** cannot be used for sending frames.\n    //\n    // * A stream transitions from this state to \"closed\" when a frame that contains a END_STREAM\n    //   flag is received, or when either peer sends a RST_STREAM frame.\n    // * An endpoint MAY send or receive PRIORITY frames in this state to reprioritize the stream.\n    // * WINDOW_UPDATE can be sent by a peer that has sent a frame bearing the END_STREAM flag.\n\n    case 'HALF_CLOSED_LOCAL':\n      if (RST_STREAM || receiving && frame.flags.END_STREAM) {\n        this._setState('CLOSED');\n      } else if (BLOCKED || ALTSVC || receiving || PRIORITY || sending && WINDOW_UPDATE) {\n        /* No state change */\n      } else {\n        connectionError = 'PROTOCOL_ERROR';\n      }\n\n      break;\n    // A stream that is **half closed (remote)** is no longer being used by the peer to send frames.\n    // In this state, an endpoint is no longer obligated to maintain a receiver flow control window\n    // if it performs flow control.\n    //\n    // * If an endpoint receives additional frames for a stream that is in this state it MUST\n    //   respond with a stream error of type STREAM_CLOSED.\n    // * A stream can transition from this state to \"closed\" by sending a frame that contains a\n    //   END_STREAM flag, or when either peer sends a RST_STREAM frame.\n    // * An endpoint MAY send or receive PRIORITY frames in this state to reprioritize the stream.\n    // * A receiver MAY receive a WINDOW_UPDATE frame on a \"half closed (remote)\" stream.\n\n    case 'HALF_CLOSED_REMOTE':\n      if (RST_STREAM || sending && frame.flags.END_STREAM) {\n        this._setState('CLOSED');\n      } else if (BLOCKED || ALTSVC || sending || PRIORITY || receiving && WINDOW_UPDATE) {\n        /* No state change */\n      } else {\n        connectionError = 'PROTOCOL_ERROR';\n      }\n\n      break;\n    // The **closed** state is the terminal state.\n    //\n    // * An endpoint MUST NOT send frames on a closed stream. An endpoint that receives a frame\n    //   after receiving a RST_STREAM or a frame containing a END_STREAM flag on that stream MUST\n    //   treat that as a stream error of type STREAM_CLOSED.\n    // * WINDOW_UPDATE, PRIORITY or RST_STREAM frames can be received in this state for a short\n    //   period after a frame containing an END_STREAM flag is sent.  Until the remote peer receives\n    //   and processes the frame bearing the END_STREAM flag, it might send either frame type.\n    //   Endpoints MUST ignore WINDOW_UPDATE frames received in this state, though endpoints MAY\n    //   choose to treat WINDOW_UPDATE frames that arrive a significant time after sending\n    //   END_STREAM as a connection error of type PROTOCOL_ERROR.\n    // * If this state is reached as a result of sending a RST_STREAM frame, the peer that receives\n    //   the RST_STREAM might have already sent - or enqueued for sending - frames on the stream\n    //   that cannot be withdrawn. An endpoint that sends a RST_STREAM frame MUST ignore frames that\n    //   it receives on closed streams after it has sent a RST_STREAM frame. An endpoint MAY choose\n    //   to limit the period over which it ignores frames and treat frames that arrive after this\n    //   time as being in error.\n    // * An endpoint might receive a PUSH_PROMISE frame after it sends RST_STREAM. PUSH_PROMISE\n    //   causes a stream to become \"reserved\". If promised streams are not desired, a RST_STREAM\n    //   can be used to close any of those streams.\n\n    case 'CLOSED':\n      if (PRIORITY || sending && RST_STREAM || receiving && WINDOW_UPDATE || receiving && this._closedByUs && (this._closedWithRst || RST_STREAM || ALTSVC)) {\n        /* No state change */\n      } else {\n        streamError = 'STREAM_CLOSED';\n      }\n\n      break;\n  } // Noting that the connection was closed by the other endpoint. It may be important in edge cases.\n  // For example, when the peer tries to cancel a promised stream, but we already sent every data\n  // on it, then the stream is in CLOSED state, yet we want to ignore the incoming RST_STREAM.\n\n\n  if (this.state === 'CLOSED' && previousState !== 'CLOSED') {\n    this._closedByUs = sending;\n    this._closedWithRst = RST_STREAM;\n  } // Sending/receiving a PUSH_PROMISE\n  //\n  // * Sending a PUSH_PROMISE frame marks the associated stream for later use. The stream state\n  //   for the reserved stream transitions to \"reserved (local)\".\n  // * Receiving a PUSH_PROMISE frame marks the associated stream as reserved by the remote peer.\n  //   The state of the stream becomes \"reserved (remote)\".\n\n\n  if (PUSH_PROMISE && !connectionError && !streamError) {\n    /* This assertion must hold, because _transition is called immediately when a frame is written\n       to the stream. If it would be called when a frame gets out of the input queue, the state\n       of the reserved could have been changed by then. */\n    assert(frame.promised_stream.state === 'IDLE', frame.promised_stream.state);\n\n    frame.promised_stream._setState(sending ? 'RESERVED_LOCAL' : 'RESERVED_REMOTE');\n\n    frame.promised_stream._initiated = sending;\n  } // Signaling how sending/receiving this frame changes the active stream count (-1, 0 or +1)\n\n\n  if (this._initiated) {\n    var change = activeState(this.state) - activeState(previousState);\n\n    if (sending) {\n      frame.count_change = change;\n    } else {\n      frame.count_change(change);\n    }\n  } else if (sending) {\n    frame.count_change = 0;\n  } // Common error handling.\n\n\n  if (connectionError || streamError) {\n    var info = {\n      error: connectionError,\n      frame: frame,\n      state: this.state,\n      closedByUs: this._closedByUs,\n      closedWithRst: this._closedWithRst\n    }; // * When sending something invalid, throwing an exception, since it is probably a bug.\n\n    if (sending) {\n      this._log.error(info, 'Sending illegal frame.');\n\n      return this.emit('error', new Error('Sending illegal frame (' + frame.type + ') in ' + this.state + ' state.'));\n    } // * In case of a serious problem, emitting and error and letting someone else handle it\n    //   (e.g. closing the connection)\n    // * When receiving something invalid, sending an RST_STREAM using the `reset` method.\n    //   This will automatically cause a transition to the CLOSED state.\n    else {\n        this._log.error(info, 'Received illegal frame.');\n\n        if (connectionError) {\n          this.emit('connectionError', connectionError);\n        } else {\n          this.reset(streamError);\n          this.emit('error', streamError);\n        }\n      }\n  }\n}; // Bunyan serializers\n// ------------------\n\n\nexports.serializers = {};\nvar nextId = 0;\n\nexports.serializers.s = function (stream) {\n  if (!('_id' in stream)) {\n    stream._id = nextId;\n    nextId += 1;\n  }\n\n  return stream._id;\n};","map":null,"metadata":{},"sourceType":"script"}