{"ast":null,"code":"var assert = require('assert');\n\nvar Serializer = require('./framer').Serializer;\n\nvar Deserializer = require('./framer').Deserializer;\n\nvar Compressor = require('./compressor').Compressor;\n\nvar Decompressor = require('./compressor').Decompressor;\n\nvar Connection = require('./connection').Connection;\n\nvar Duplex = require('stream').Duplex;\n\nvar Transform = require('stream').Transform;\n\nexports.Endpoint = Endpoint; // The Endpoint class\n// ==================\n// Public API\n// ----------\n// - **new Endpoint(log, role, settings, filters)**: create a new Endpoint.\n//\n//   - `log`: bunyan logger of the parent\n//   - `role`: 'CLIENT' or 'SERVER'\n//   - `settings`: initial HTTP/2 settings\n//   - `filters`: a map of functions that filter the traffic between components (for debugging or\n//     intentional failure injection).\n//\n//     Filter functions get three arguments:\n//     1. `frame`: the current frame\n//     2. `forward(frame)`: function that can be used to forward a frame to the next component\n//     3. `done()`: callback to signal the end of the filter process\n//\n//     Valid filter names and their position in the stack:\n//     - `beforeSerialization`: after compression, before serialization\n//     - `beforeCompression`: after multiplexing, before compression\n//     - `afterDeserialization`: after deserialization, before decompression\n//     - `afterDecompression`: after decompression, before multiplexing\n//\n// * **Event: 'stream' (Stream)**: 'stream' event forwarded from the underlying Connection\n//\n// * **Event: 'error' (type)**: signals an error\n//\n// * **createStream(): Stream**: initiate a new stream (forwarded to the underlying Connection)\n//\n// * **close([error])**: close the connection with an error code\n// Constructor\n// -----------\n// The process of initialization:\n\nfunction Endpoint(log, role, settings, filters) {\n  Duplex.call(this); // * Initializing logging infrastructure\n\n  this._log = log.child({\n    component: 'endpoint',\n    e: this\n  }); // * First part of the handshake process: sending and receiving the client connection header\n  //   prelude.\n\n  assert(role === 'CLIENT' || role === 'SERVER');\n\n  if (role === 'CLIENT') {\n    this._writePrelude();\n  } else {\n    this._readPrelude();\n  } // * Initialization of component. This includes the second part of the handshake process:\n  //   sending the first SETTINGS frame. This is done by the connection class right after\n  //   initialization.\n\n\n  this._initializeDataFlow(role, settings, filters || {}); // * Initialization of management code.\n\n\n  this._initializeManagement(); // * Initializing error handling.\n\n\n  this._initializeErrorHandling();\n}\n\nEndpoint.prototype = Object.create(Duplex.prototype, {\n  constructor: {\n    value: Endpoint\n  }\n}); // Handshake\n// ---------\n\nvar CLIENT_PRELUDE = new Buffer('PRI * HTTP/2.0\\r\\n\\r\\nSM\\r\\n\\r\\n'); // Writing the client header is simple and synchronous.\n\nEndpoint.prototype._writePrelude = function _writePrelude() {\n  this._log.debug('Sending the client connection header prelude.');\n\n  this.push(CLIENT_PRELUDE);\n}; // The asynchronous process of reading the client header:\n\n\nEndpoint.prototype._readPrelude = function _readPrelude() {\n  // * progress in the header is tracker using a `cursor`\n  var cursor = 0; // * `_write` is temporarily replaced by the comparator function\n\n  this._write = function _temporalWrite(chunk, encoding, done) {\n    // * which compares the stored header with the current `chunk` byte by byte and emits the\n    //   'error' event if there's a byte that doesn't match\n    var offset = cursor;\n\n    while (cursor < CLIENT_PRELUDE.length && cursor - offset < chunk.length) {\n      if (CLIENT_PRELUDE[cursor] !== chunk[cursor - offset]) {\n        this._log.fatal({\n          cursor: cursor,\n          offset: offset,\n          chunk: chunk\n        }, 'Client connection header prelude does not match.');\n\n        this._error('handshake', 'PROTOCOL_ERROR');\n\n        return;\n      }\n\n      cursor += 1;\n    } // * if the whole header is over, and there were no error then restore the original `_write`\n    //   and call it with the remaining part of the current chunk\n\n\n    if (cursor === CLIENT_PRELUDE.length) {\n      this._log.debug('Successfully received the client connection header prelude.');\n\n      delete this._write;\n      chunk = chunk.slice(cursor - offset);\n\n      this._write(chunk, encoding, done);\n    }\n  };\n}; // Data flow\n// ---------\n//     +---------------------------------------------+\n//     |                                             |\n//     |   +-------------------------------------+   |\n//     |   | +---------+ +---------+ +---------+ |   |\n//     |   | | stream1 | | stream2 | |   ...   | |   |\n//     |   | +---------+ +---------+ +---------+ |   |\n//     |   |             connection              |   |\n//     |   +-------------------------------------+   |\n//     |             |                 ^             |\n//     |        pipe |                 | pipe        |\n//     |             v                 |             |\n//     |   +------------------+------------------+   |\n//     |   |    compressor    |   decompressor   |   |\n//     |   +------------------+------------------+   |\n//     |             |                 ^             |\n//     |        pipe |                 | pipe        |\n//     |             v                 |             |\n//     |   +------------------+------------------+   |\n//     |   |    serializer    |   deserializer   |   |\n//     |   +------------------+------------------+   |\n//     |             |                 ^             |\n//     |     _read() |                 | _write()    |\n//     |             v                 |             |\n//     |      +------------+     +-----------+       |\n//     |      |output queue|     |input queue|       |\n//     +------+------------+-----+-----------+-------+\n//                   |                 ^\n//            read() |                 | write()\n//                   v                 |\n\n\nfunction createTransformStream(filter) {\n  var transform = new Transform({\n    objectMode: true\n  });\n  var push = transform.push.bind(transform);\n\n  transform._transform = function (frame, encoding, done) {\n    filter(frame, push, done);\n  };\n\n  return transform;\n}\n\nfunction pipeAndFilter(stream1, stream2, filter) {\n  if (filter) {\n    stream1.pipe(createTransformStream(filter)).pipe(stream2);\n  } else {\n    stream1.pipe(stream2);\n  }\n}\n\nEndpoint.prototype._initializeDataFlow = function _initializeDataFlow(role, settings, filters) {\n  var firstStreamId, compressorRole, decompressorRole;\n\n  if (role === 'CLIENT') {\n    firstStreamId = 1;\n    compressorRole = 'REQUEST';\n    decompressorRole = 'RESPONSE';\n  } else {\n    firstStreamId = 2;\n    compressorRole = 'RESPONSE';\n    decompressorRole = 'REQUEST';\n  }\n\n  this._serializer = new Serializer(this._log);\n  this._deserializer = new Deserializer(this._log);\n  this._compressor = new Compressor(this._log, compressorRole);\n  this._decompressor = new Decompressor(this._log, decompressorRole);\n  this._connection = new Connection(this._log, firstStreamId, settings);\n  pipeAndFilter(this._connection, this._compressor, filters.beforeCompression);\n  pipeAndFilter(this._compressor, this._serializer, filters.beforeSerialization);\n  pipeAndFilter(this._deserializer, this._decompressor, filters.afterDeserialization);\n  pipeAndFilter(this._decompressor, this._connection, filters.afterDecompression);\n\n  this._connection.on('ACKNOWLEDGED_SETTINGS_HEADER_TABLE_SIZE', this._decompressor.setTableSizeLimit.bind(this._decompressor));\n\n  this._connection.on('RECEIVING_SETTINGS_HEADER_TABLE_SIZE', this._compressor.setTableSizeLimit.bind(this._compressor));\n};\n\nvar noread = {};\n\nEndpoint.prototype._read = function _read() {\n  this._readableState.sync = true;\n  var moreNeeded = noread,\n      chunk;\n\n  while (moreNeeded && (chunk = this._serializer.read())) {\n    moreNeeded = this.push(chunk);\n  }\n\n  if (moreNeeded === noread) {\n    this._serializer.once('readable', this._read.bind(this));\n  }\n\n  this._readableState.sync = false;\n};\n\nEndpoint.prototype._write = function _write(chunk, encoding, done) {\n  this._deserializer.write(chunk, encoding, done);\n}; // Management\n// --------------\n\n\nEndpoint.prototype._initializeManagement = function _initializeManagement() {\n  this._connection.on('stream', this.emit.bind(this, 'stream'));\n};\n\nEndpoint.prototype.createStream = function createStream() {\n  return this._connection.createStream();\n}; // Error handling\n// --------------\n\n\nEndpoint.prototype._initializeErrorHandling = function _initializeErrorHandling() {\n  this._serializer.on('error', this._error.bind(this, 'serializer'));\n\n  this._deserializer.on('error', this._error.bind(this, 'deserializer'));\n\n  this._compressor.on('error', this._error.bind(this, 'compressor'));\n\n  this._decompressor.on('error', this._error.bind(this, 'decompressor'));\n\n  this._connection.on('error', this._error.bind(this, 'connection'));\n\n  this._connection.on('peerError', this.emit.bind(this, 'peerError'));\n};\n\nEndpoint.prototype._error = function _error(component, error) {\n  this._log.fatal({\n    source: component,\n    message: error\n  }, 'Fatal error, closing connection');\n\n  this.close(error);\n  setImmediate(this.emit.bind(this, 'error', error));\n};\n\nEndpoint.prototype.close = function close(error) {\n  this._connection.close(error);\n}; // Bunyan serializers\n// ------------------\n\n\nexports.serializers = {};\nvar nextId = 0;\n\nexports.serializers.e = function (endpoint) {\n  if (!('id' in endpoint)) {\n    endpoint.id = nextId;\n    nextId += 1;\n  }\n\n  return endpoint.id;\n};","map":null,"metadata":{},"sourceType":"script"}